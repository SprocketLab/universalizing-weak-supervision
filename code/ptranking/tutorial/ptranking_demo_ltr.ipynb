{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards A Better Understanding of Typical Learning-to-rank Methods Based on PT-Ranking, Such as RankNet & LambdaRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Sigmoid Function & Logistic Function\n",
    "\n",
    "A sigmoid function **having a characteristic of S-shaped curve** is defined as follows,\n",
    "\n",
    "$$ f(x)=\\frac{1}{1+\\exp(-x)} $$\n",
    "\n",
    "A logistic function is defined as,\n",
    "\n",
    "$$ f(x)=\\frac{L}{1+\\exp(-k(x-x_0))} $$\n",
    "\n",
    "Commonly, with parameters ($k=1$, $x_0=0$, $L=1$), the standard logistic function is just a sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'f(x)')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(-10, 10, 0.1)\n",
    "f = 1. / (1. + np.exp(-x))\n",
    "\n",
    "plt.plot(x, f)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 RankNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two documents $d_i$ and $d_j$ that are represented as feature vectors $\\mathbf{x}_i$ and $\\mathbf{x}_j$, let $f$ be the ranking function, the ranking scores will be $s_i=f(\\mathbf{x}_i)$ and $s_j=f(\\mathbf{x}_j)$, the probability $p_{ij}$ indicating $d_i$ should be ranked higher than $d_j$ is given as\n",
    "\n",
    "$$ p_{ij}=\\frac{1}{1+\\exp(-(s_i-s_j))} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loss of pairwise classification\n",
    "\n",
    "Let $\\bar{p_{ij}}$ be the known probability that $d_i$ should be ranked higher than $d_j$, we then apply the cross entropy cost function that penalizes the deviation of the model output probabilities from the desired probabilities,\n",
    "\n",
    "$$ C=-\\bar{p_{ij}} \\log(p_{ij}) - (1-\\bar{p_{ij}})\\log(1-p_{ij}) $$\n",
    "\n",
    "For a given query, let $S_{ij}\\in \\{-1, 0, 1\\}$ be defined to be 1 if doc-i has been labeled to be more relevant than doc-j, âˆ’1 if doc-i has been labeled to be less relevant than doc-j, and 0 if they have the same label. In particular, we assume that the desired ranking is deterministically known, so that $\\bar{p_{ij}}=\\frac{1}{2}(1+S_{ij})$. Combining the above two equations gives\n",
    "\n",
    "$$ C=\\frac{1}{2}(1-S_{ij})(s_i-s_j) + \\log(1+\\exp(-(s_i-s_j))) $$\n",
    "\n",
    "The cost is comfortingly symmetric (swapping $i$ and $j$ and changing the sign of $S_{ij}$ should leave the cost invariant): for $S_{ij}=1$,\n",
    "\n",
    "$$ C=\\log(1+\\exp(-(s_i-s_j))) $$\n",
    "\n",
    "while for $S_{ij}=-1$,\n",
    "\n",
    "$$ C=\\log(1+\\exp(-(s_j-s_i))) $$\n",
    "\n",
    "Note that when $s_i = s_j$, the cost is $\\log2$, so the model incorporates a margin (that is, documents with different labels, but to which the model assigns the same scores, are still pushed away from each other in the ranking). Also, asymptotically, the cost becomes linear (if the scores give the wrong ranking), or zero (if they give the correct ranking).\n",
    "\n",
    "For the gradient, essentially we have\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial s_{i}}=\\frac{1}{2}(1-S_{ij})-\\frac{1}{1+e^{(s_{i}-s_{j})}}=-\\frac{\\partial C}{\\partial s_{j}}$$\n",
    "\n",
    "Furthermore,\n",
    "\n",
    "$\\frac{\\partial^{2} C}{\\partial s_{i}^{2}}=\\sigma (s_{j}-s_{i})(1-\\sigma (s_{j}-s_{i}))\n",
    "=\\frac{1}{1+e^{(s_{i}-s_{j})}} (1-\\frac{1}{1+e^{(s_{i}-s_{j})}})=-\\frac{\\partial^{2} C}{\\partial s_{j}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 LambdaRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key observation of LambdaRank is that: in order to train a model, we don't need the costs themselves, and we only need the gradients of the costs w.r.t. the model scores.\n",
    "\n",
    "We denote the gradient $\\frac{\\partial C}{\\partial s_{i}}$ as $\\lambda_{ij}$, namely\n",
    "\n",
    "$\n",
    "\\lambda_{ij}=\\frac{\\partial C(s_{i}-s_{j})}{\\partial s_{i}}=\\frac{1}{2}(1-S_{ij})-\\frac{1}{1+e^{(s_{i}-s_{j})}}\n",
    "$\n",
    "\n",
    "LambdaRank mainly differs from RankNet in that: modifying the above gradient by simply multiplying by the size of change in a particular metric $|\\Delta nDCG|$ (say, in term of $nDCG$) given by swapping the rank positions of $d_i$ and $d_j$ while leaving the rank positions of other documents unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 An Empirical Study of RankNet and LambdaRank Based on PT-Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Declare a plot function for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_var(list_vals, lbl=None):\n",
    "    X = np.arange(start=1, stop=len(list_vals)+1).tolist()\n",
    "    if lbl is not None:\n",
    "        plt.plot(X, list_vals, label=lbl)\n",
    "    else:\n",
    "        plt.plot(X, list_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.2 Specify dataset, output directory, initialize the evaluation object, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from ptranking.ltr_adhoc.eval.ltr import LTREvaluator\n",
    "from ptranking.eval.parameter import DataSetting, EvalSetting, ModelParameter, ScoringFunctionParameter\n",
    "\n",
    "''' dataset identifier '''\n",
    "data_id = 'MQ2008_Super'\n",
    "\n",
    "''' directory of the corresponding dataset '''\n",
    "# dir_data = '/Users/dryuhaitao/WorkBench/Corpus/LETOR4.0/MQ2007/'\n",
    "# dir_data = '/Users/solar/WorkBench/Datasets/L2R/LETOR4.0/MQ2008/'\n",
    "dir_data = '../MQ2008/'\n",
    "\n",
    "''' output directory for results '''\n",
    "dir_output='../output/'\n",
    "#dir_output = '/Users/solar/WorkBench/CodeBench/PyCharmProject/Project_output/Out_L2R/'\n",
    "\n",
    "''' the main class for conducting training & testing '''\n",
    "ltr_evaluator = LTREvaluator()\n",
    "\n",
    "debug = True # in a debug mode, we just check whether the model can operate\n",
    "\n",
    "''' using the default setting for loading dataset & using the default setting for evaluation '''\n",
    "ltr_evaluator.set_eval_setting(debug=debug, dir_output=dir_output)\n",
    "ltr_evaluator.set_data_setting(debug=debug, data_id=data_id, dir_data=dir_data)\n",
    "data_dict = ltr_evaluator.get_default_data_setting()\n",
    "eval_dict = ltr_evaluator.get_default_eval_setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.3 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold- 1\n",
      "data_dict {'data_id': 'MQ2008_Super', 'dir_data': '../MQ2008/', 'min_docs': 10, 'min_rele': 1, 'scale_data': False, 'scaler_id': None, 'scaler_level': None, 'train_presort': True, 'validation_presort': True, 'test_presort': True, 'train_batch_size': 1, 'validation_batch_size': 1, 'test_batch_size': 1, 'unknown_as_zero': False, 'binary_rele': False, 'num_features': 46, 'has_comment': True, 'label_type': <LABEL_TYPE.MultiLabel: 1>, 'max_rele_level': 2, 'fold_num': 5}\n",
      "../MQ2008/Fold1/train.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../MQ2008/Fold1/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6844bcdd44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m''' load the dataset '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvali_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mltr_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/universalizing-weak-supervision/code/ptranking/ptranking/ltr_adhoc/eval/ltr.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, eval_dict, data_dict, fold_k)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0minput_eval_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0meval_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# required when enabling masking data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         train_data = LTRDataset(file=file_train, split_type=SPLIT_TYPE.Train, batch_size=train_batch_size,\n\u001b[0;32m--> 146\u001b[0;31m                                 shuffle=True, presort=train_presort, data_dict=data_dict, eval_dict=input_eval_dict)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         test_data = LTRDataset(file=file_test, split_type=SPLIT_TYPE.Test, shuffle=False, data_dict=data_dict,\n",
      "\u001b[0;32m~/universalizing-weak-supervision/code/ptranking/ptranking/data/data_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, split_type, file, data_id, data_dict, eval_dict, batch_size, presort, shuffle, hot, buffer, num_features)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0mscaler_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scaler_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'scaler_id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 list_Qs = iter_queries(in_file=file, presort=self.presort, data_dict=data_dict, scale_data=scale_data,\n\u001b[0;32m--> 655\u001b[0;31m                                        scaler_id=scaler_id, perquery_file=perquery_file, buffer=buffer)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mlist_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_Qs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/universalizing-weak-supervision/code/ptranking/ptranking/data/data_utils.py\u001b[0m in \u001b[0;36miter_queries\u001b[0;34m(in_file, presort, data_dict, scale_data, scaler_id, perquery_file, buffer)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0mlist_Qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0mdict_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_comment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../MQ2008/Fold1/train.txt'"
     ]
    }
   ],
   "source": [
    "''' load the dataset '''\n",
    "train_data, test_data, vali_data = ltr_evaluator.load_data(eval_dict=eval_dict, data_dict=data_dict, fold_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.list_torch_Qs[1][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.3 Configuration of the neural scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' using the default setting for constructing a neural scoring function '''\n",
    "ltr_evaluator.set_scoring_function_setting(debug=debug, data_dict=data_dict)\n",
    "sf_para_dict = ltr_evaluator.get_default_scoring_function_setting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.4 An example play - RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' the parameter setting for a model '''\n",
    "model_id = 'RankNet' # The specified model with default parameters\n",
    "ltr_evaluator.set_model_setting(debug=debug, model_id=model_id)\n",
    "model_para_dict = ltr_evaluator.get_default_model_setting()\n",
    "\n",
    "''' basic check before loading the ranker '''\n",
    "ltr_evaluator.setup_eval(data_dict=data_dict, eval_dict=eval_dict, sf_para_dict=sf_para_dict, model_para_dict=model_para_dict)\n",
    "\n",
    "''' initialize the ranker '''\n",
    "ranknet   = ltr_evaluator.load_ranker(sf_para_dict=sf_para_dict, model_para_dict=model_para_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.4.1 Train RankNet and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ranknet_losses, ranknet_train_ndcgs, ranknet_test_ndcgs = ltr_evaluator.naive_train(ranker=ranknet, eval_dict=eval_dict, train_data=train_data, test_data=test_data)\n",
    "\n",
    "show_var(ranknet_losses, lbl='Training loss') # show the variation of loss\n",
    "plt.legend()\n",
    "plt.title('RankNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cutoffs = [1, 3, 5, 10, 20, 50]\n",
    "\n",
    "for i in range(len(cutoffs)):\n",
    "    k = cutoffs[i]\n",
    "    show_var(ranknet_train_ndcgs[:, i], lbl='Train-nDCG@'+str(k))\n",
    "plt.legend()\n",
    "plt.title('RankNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(cutoffs)):\n",
    "    k = cutoffs[i]\n",
    "    show_var(ranknet_test_ndcgs[:, i], lbl='Test-nDCG@'+str(k))\n",
    "plt.legend()\n",
    "plt.title('RankNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 An example play - LambdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' the parameter setting for a model '''\n",
    "model_id = 'LambdaRank' # The specified model with default parameters\n",
    "data_dict = ltr_evaluator.get_default_data_setting()\n",
    "# ltr_evaluator.set_model_setting(debug=debug, model_id=model_id, data_dict=data_dict) # data_dict argument is required\n",
    "ltr_evaluator.set_model_setting(debug=debug, model_id=model_id) # data_dict argument is required\n",
    "model_para_dict = ltr_evaluator.get_default_model_setting()\n",
    "\n",
    "''' basic check before loading the ranker '''\n",
    "ltr_evaluator.setup_eval(data_dict=data_dict, eval_dict=eval_dict, sf_para_dict=sf_para_dict, model_para_dict=model_para_dict)\n",
    "\n",
    "''' initialize the ranker '''\n",
    "lambdarank   = ltr_evaluator.load_ranker(sf_para_dict=sf_para_dict, model_para_dict=model_para_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Train LambdaRank and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lambdarank_losses, lambdarank_train_ndcgs, lambdarank_test_ndcgs = ltr_evaluator.naive_train(ranker=lambdarank, eval_dict=eval_dict, train_data=train_data, test_data=test_data)\n",
    "\n",
    "show_var(lambdarank_losses, lbl='Training loss') # show the variation of loss\n",
    "plt.legend()\n",
    "plt.title('LambdaRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(cutoffs)):\n",
    "    k = cutoffs[i]\n",
    "    show_var(lambdarank_train_ndcgs[:, i], lbl='Train-nDCG@'+str(k))\n",
    "plt.legend()\n",
    "plt.title('LambdaRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(cutoffs)):\n",
    "    k = cutoffs[i]\n",
    "    show_var(lambdarank_test_ndcgs[:, i], lbl='Test-nDCG@'+str(k))\n",
    "plt.legend()\n",
    "plt.title('LambdaRank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws-cardinality",
   "language": "python",
   "name": "ws-cardinality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
